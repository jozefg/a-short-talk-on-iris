\documentclass{amsart}
\usepackage{amsmath, amssymb}
\usepackage{stmaryrd}
\usepackage{mathpartir}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{iris}

\newcommand{\provesJ}[3]{#1 \mathop{\vert} #2 \proves #3}
\newcommand{\provesIffJ}[3]{#1 \mathop{\vert} #2 \provesIff #3}
\newcommand{\limplies}{\to}
\newcommand{\forces}{\Vdash}
\newcommand{\defs}{\triangleq}
\newcommand{\EMP}{\textlog{Emp}}

\title{Iris, Briefly}
\author{Daniel Gratzer}
\date{\today}

\begin{document}
\maketitle

The purpose of this note is to briefly introduce those familiar with
some variant of concurrent separation
logic~\citep{OHearn:02,OHearn:07} to the Iris
logic~\citep{Jung:15,Jung:16,Krebbers:17,Jung:17}. Like O'Hearn's
logic, Iris presents a framework for reasoning about programs with
concurrency and shared state. Unlike Concurrent Separation Logic, Iris
is not a collection of inferences rules defining axiomitizing a
Hoare-triple-like judgment~\citep{Hoare:69}.

Iris comes from nearly 15 years after the first introduction of
concurrent separation logic and in that time there has been an
explosion of concurrent separation logics~\citep{Parkinson:10}. Each
new program or idiom has seemed to spawn a new concurrent separation
logic, more complicated than any that came before it, which allows the
verification of most of the previously possible programs and this new
one. This state of affairs was highly unsatisfying for a number of
reasons, chief among them being that there was no endpoint in
sight. None of these logics claimed to be a clean or complete solution
and the expectation was that in a years time the work put into this
logic must be redone in order to extend it to a new class of
programs. This constant churn also damaged the usability of each
logic, there was no point in creating tooling or any library of
verified programs in a logic that was to be obsoleted in 6 months.

Given this state of affairs, Iris is an attempt to provide a unified
foundation for a \emph{variety} of concurrent separation
logics. Rather than fixing a particular collection of rules and baking
in a few concurrency patterns Iris provides the tools needed to encode
these rules. This means that the formal definition of Iris makes no
mention of a particular form of concurrency, nor indeed a particular
programming language of any sort. There is no notion of Hoare triples
or weakest preconditions, let alone invariants or even really ghost
state. All of these notions are instead encoded which has crucially
left them available to change. Indeed, the central difference between
Iris when originally proposed~\citep{Jung:15} and the version
currently used~\citep{Jung:17} is that more and more of Iris has been
encoded rather than primitively given.

In this note we discuss the base system of Iris and how we can move
from the handful of modalities added to higher-order bunched
implication logic to a full blown separation logic. To finish, we
shall briefly discuss some of the surprising extensions made to Iris.

\section{The Base Logic of Iris}\label{sec:logic}

It has long been folklore~\footnote{Listen, it's called folklore
  because I don't know who to cite for this observation} that
separation logic can been understood as an instance of bunched
implication logic. Bunched implication logic is a logic generated by a
very simple idea: rather than just having one form of expressing that
two propositions simultaneously hold, we have two. This idea
generalizes the observation in separation logic that there are two
reasonable ways that two proposition can be said to hold together on a
heap.
\begin{align*}
  h \forces P_1 \land P_2 &\defs h \forces P_1 \land h \forces P_2\\
  h \forces P_1 \sep P_2 &\defs \Exists h_1, h_2. h_1 \uplus h_2 = h
                           \land h_1 \forces P_1
                           \land h_2 \forces P_2
\end{align*}
In bunched implication logic we move away from the particulars of
owning a heap and consider having $\land$ and $\sep$ coexisting in the
same logic. As is usual, there is a corresponding nullary version of
conjuction for each of the two forms, written $\TRUE$ and $\EMP$
respectively. In order to make this applicable to separation logic, our
bunched implication logic is substructural, with the following rule
being inadmissible.
\[
  \inferrule{ }{P \vdash P \sep P}
\]
On the other hand, $\land$ behaves in the structural way one would
expect from intuitionistic logic with all four of the following rules
being derivable.
\begin{mathpar}
  \inferrule{ }{P \vdash \TRUE} \and
  \inferrule{P \vdash Q \land R}{P \vdash Q \\ P \vdash R} \and
  \inferrule{P \vdash Q \\ P \vdash R}{P \vdash Q \land R} \and
  \inferrule{ }{P \land Q \vdash Q \land P}
\end{mathpar}
The precise properties of $\sep$ are more up for debate. In
particular, it's conceivable to discuss a linear version of $\sep$
or an affine variant. To my knowledge, no separation logic makes use
of an ordered separating conjunction, but it's certainly
conceivable. For Iris we will make do with an affine separating
conjuction. This means that we will assume the following rules about
$\sep$.
\begin{mathpar}
  \inferrule{ }{\EMP \dashv\vdash \TRUE} \and
  \inferrule{ }{P \sep \EMP \dashv\vdash P} \and
  \inferrule{ }{P \sep Q \vdash Q \sep P} \and
  \inferrule{ }{(P \sep Q) \sep R \vdash P \sep (Q \sep R)} \and
  \inferrule{P_i \vdash Q_i}{P_1 \sep P_2 \vdash Q_1 \sep Q_2}
\end{mathpar}
One may reasonably observe that these rules are somewhat clunkier than
the rules governing $\land$. This is largely due to the structure of
the proof theory. There's a more natural presentation of bunched
implication logic, as given in \citet{OHearn:99}. In this presentation
the judgmental structure is richer so that $\land$ and $\sep$ are just
straightforward internalizations of ambient judgmental structure. In
particular, rather than a two-place relation between propositions as
our $\vdash$ is, this proof theory relates nested trees of
propositions (bunches) to propositions.

One outstanding question is the standing of implication in this
logic. In normal propositional
\[
  \mprset{fraction={===}}
  \inferrule{
    P_1 \vdash P_2 \limplies P_3
  }{P_1 \land P_2 \vdash P_3}
\]
Our separation conjunction though, can also be equipped with a
function space. It is defined by a similar rule
\[
  \mprset{fraction={===}}
  \inferrule{
    P_1 \vdash P_2 \wand P_3
  }{P_1 \sep P_2 \vdash P_3}
\]
With these four connectives we have the foundations of bunched
implication logic and with it, Iris. The integration of disjunction
can be done with relatively little effort. Let us now discuss the
components on top of propositional BI that Iris makes use of.

\subsection{Higher-Order Bunched Implication Logic}\label{subsec:hol}

The generalization of propositional bunched implication logic to
higher-order bunched implication logic is an important but still quite
simple move. In order to do this, we first must sketch out the term
structure of the language the logic is constructed over. As a matter
of ergonomics the actual iris-coq formalization~\citep{iris-coq} uses
the native Coq terms as the language the logic is built
over\footnote{This trick can by formally justified denotational: the
  model of Iris lives in the topos of trees which supports a full
  model of Coq.}. On paper, this trick is less appealing so we must be
upfront about what language we are to use.

Our language will be a variant of System T to which we freely add
unit, void, sums, and products. Of course, as this is the language of
a higher-order logic the language also contains a distinguished type,
$\Omega$, which serves as the type of propositions. This type has
operators corresponding to every proposition in our language. Since
Iris is a higher-order logic rather than a type theory there is no
operator inflating a proposition into a type nor any sort of
dependence, this simplifies matters with no real loss of utility. As
is usual with higher-order logics, define the language relative to a
signature of constants and axioms. This signature will be important
for the integration of cameras into the logic, see
Subsection~\ref{subsec:ghost}. We shall elide the formal definition of
this language and trust the reader to be familiar with standard
presentations of such languages.

With the language fixed, the addition of higher-order aspect of the
logic is relatively mundane. In particular, in this setting there is
no real choice of quantifiers as discussed in \citet{OHearn:99}. Terms
merely exist, they express no form of ownership and therefore we have
something akin to O'Hearn's additive quantifiers. The judgment for the
truth of a proposition is altered to
\[
  \provesJ{\Gamma}{P}{Q}
\]
where $\Gamma$ is a context of term variables so that
$\Gamma \proves P, Q : \Omega$. The rules for universal
quantification, existential quantification, and equality are the usual
adjoint formulation due to Lawvere~\citep{Lawvere:70}.
\begin{mathpar}
  \mprset{fraction={===}}
  \inferrule{
    \provesJ{\Gamma, x : \tau}{P}{Q}
  }{\provesJ{\Gamma}{P}{\All x : \tau. Q}}\and
  \mprset{fraction={===}}
  \inferrule{
    \provesJ{\Gamma, x : \tau}{P}{Q}
  }{\provesJ{\Gamma}{\Exists x : \tau. P}{Q}}\and
  \mprset{fraction={===}}
  \inferrule{
    \provesJ{\Gamma, x : \tau}{\TRUE}{Q}
  }{\provesJ{\Gamma, x : \tau, y : \tau}{x = y}{Q}}
\end{mathpar}
In order for these to be sensible they must of course be paired with
the appropriate substitution rule.
\[
  \inferrule{
    \Gamma \proves t : \tau\\
    \provesJ{\Gamma, x : \tau}{P}{Q}
  }{\provesJ{\Gamma}{[t/x]P}{[t/x]Q}}
\]
The rules for bunched implications are unchanged by the addition of a
context and so there is really nothing else to note on this subject.

\subsection{Integrating Ghost State Parametrically}\label{subsec:ghost}

So far our logic provides a framework for discussing ownership through
$\sep$ and $\wand$ but it is essentially barren. There is nothing in
the language of propositions that actually \emph{owns} anything. What
is needed is a new proposition which allows for something to be
owned. For this we need a notion of resources which can be manipulated
by the Iris logic. These are so called cameras,\footnote{This is
  sometimes spelled CMRA (complete metric resource algebra). This
  acronym is especially confusing when it became apparent that cameras
  needn't be complete.} a
generalization of partial commutative monoids. Put in an extremely
terse way: cameras are (almost) partial commutative monoids internally
to the topos of trees. It is well worth it, however, to unpack this
statement.

A camera is an algebraic structure on a set $M$ consisting of
\begin{itemize}
\item A family of equality relations: $x \nequiv{n} y$.
\item An operator $\mtimes : M \times M \to M$.
\item An operator $\mcore{-} : M \to \maybe{M} = M \uplus \{\bot\}$.
\item An operator $\mval(-) : M \to \pset{\mathbb{N}}$
\end{itemize}
Intuitively a camera is a partial commutive monoid equipped with an
operator telling us the local unit for an element if one exists. The
main source of complication is Iris, as a guarded logic, is best
regarded as a step-indexed logic of sorts. This step-indexing is then
integrated into the partial commutative monoid under
consideration. In fact, this step-indexing allows us to form cameras
which depend on Iris propositions themselves. This powerful form of
recursion (cameras depend on props, props depend on cameras) is what
allows for the encoding invariants in the base logic.

The first part of this integration is that elements of the monoid can
be compared for equality up to $n$ steps. This family of equivalence
relations is required to satisfy the following two rules.
\[
  \All n. x \nequiv{n + 1} y \implies x \nequiv{n} y \qquad\qquad
  (\All n. x \nequiv{n} y) \iff x = y
\]
This structure in the literature on Iris is called an ``ordered family
of equivalences'' (OFE) and it arises quite frequently. We shall not
need it until the more extended discussion of the semantics in
Section~\ref{sec:model}. Another core requirement of a camera is that
all of the operations on it must be functional for $\nequiv{n}$ but
only up to $\nequiv{n}$. This means that, for instance,
\begin{gather*}
  x_1 \nequiv{n} x_2 \land y_1 \nequiv{n} y_2 \implies
  x_1 \mtimes y_1 \nequiv{n} x_2 \mtimes y_2\\
  x \nequiv{n} y \implies (n \in \mval(x) \iff n \in \mval(y))\\
  x \nequiv{n} y \implies \mcore{x} \nequiv{n} \mcore{y}
\end{gather*}
The operation $\mtimes$ is the multiplication of partial commutative
monoid so it is commutative and associative. Rather than making it
explicitly partial though, it is total and certain elements of the
monoid are judged to be invalid. The partiality of multiplication is
then reflected in the failure of multiplication to send valid elements
to valid elements. An element, $x$, is said to be valid for $n$ steps
when $n \in \mval(x)$. This structure is a slight enrichment over the
usual notion of partiality since it allows for the multiplication to
be defined ``up to $n$ steps''.

Validity must satisfy a few rules. Firstly if a multiplication is
valid, then any component of that multiplication must be at least as
valid: $\mval(x \mtimes y) \subseteq \mval(x)$. Slightly less
intuitively, there is an extension property associated with valid
elements: if $n \in \mval(x)$ and $x \nequiv{n} y_1 \mtimes y_2$, then
we must be able to find some $z_1, z_2$ so that $x = z_1 \times z_2$
(notice this equality is \emph{on the nose} rather than up to an
index) and where $z_i \nequiv{n} y_i$. This will prove crucial later
in the semantics: without this property it wouldn't be possible to
prove that $\later$ (see Subsection~\ref{subsec:guarded}) commutes
with $\sep$.

The last operation a camera is equipped with is the ability to
\emph{core} an element, $\mcore{x}$. This operation is explicitly
partial, explicitly returning $\bot$ in some cases. However, when
$\mcore{x}$ is defined then it is required to be idempotent and to be
a unit for $x$.

This concludes the description of the camera structure. The Iris base
logic will be defined relative to some camera $M$ with a distinguished
global unit $\epsilon$. All of the rules of inference described will
be true independent of $M$. This flexibility in the choice of $M$ is
crucial for flexibility in Iris. We needn't fix a predefined
collection of blessed cameras for use in proofs. It can be chosen by
the user and bespoke cameras may be chosen for particular proofs. At
the end of the day, the camera is internalized into the logic by the
following proposition.
\[
  \inferrule{
    \Gamma \proves t : M
  }{\Gamma \proves \ownM{t} : \Omega}
\]
The judgment $\Gamma \proves t : M$ is understood by adding $M$ as a
base type to our language and viewing each $a \in M$ as constant of
type $M$. We are also free to use the signature to add new means of
constructing terms of type $M$, thus internalizing certain operations
on $M$. The proposition $\ownM{t}$ intuitively states the ownership of
the resource $t$. The monoid structure on $M$ is internalized by
separating conjunction, so that the following rule holds.
\[
  \inferrule{
    \Gamma \proves t_1, t_2 : M
  }{\provesIffJ{\Gamma}{\ownM{t_1 \cdot t_2}}{\ownM{t_1} \sep \ownM{t_2}}}
\]
Similarly, the unital element $\epsilon$ represents holding no
resources so we have a rule for producing it (well, the formal term
corresponding to it) in any circumstances.
\[
  \inferrule{ }{\provesJ{\Gamma}{\TRUE}{\ownM{\epsilon}}}
\]
We also want to only be able to own valid elements. This is crucial
for using cameras to express invalid states when reasoning about
programs later. In order to deal with this internally to the logic,
we equip Iris with a new proposition.
\[
  \inferrule{
    \Gamma \proves t : M
  }{\Gamma \proves \mval(t) : \Omega}
\]
This judgment internalizes the validity that $M$ must come equipped
with. The issue with this is that we cannot in general state a rule
like the following:
\[
  \inferrule{
    \neg \mval(t)
  }{\provesJ{\Gamma}{\mval(t)}{\FALSE} : \Omega}
\]
The first issue is that $\mval(-)$ is not a boolean value, but a set
of indices at which it is valid. The second more serious issue is that
$t$ is a formal term which contains variables from the context $t$. It
is not really a member of the set $M$. Instead we rely on the ability
to parameterize Iris with a signature consisting of axioms. We first
add an axiom for every term of type $M$ which is simply a code for an
actual element $a \in M$ of the following form.
\[
  \inferrule{
    a \in M\\
    0 \not\in \mval(a)
  }{\provesJ{\Gamma}{\mval(a)}{\FALSE}}
\]
But really the family of axioms that we want is that if
$\Gamma \proves t : \tau$ and for all semantic environments
$\eta : \Gamma$, if $0 \not\in \mval(\Sem{t}_\eta)$ then
$\provesJ{\Gamma}{\mval(t)}{\FALSE}$. This axiom scheme can of course
be justified by using the denotation described in
Section~\ref{sec:model}. Though a bit hairy, this scheme does
faithfully represent the proof techniques that one can use in iris-coq
and is important for being able to practically reason about resources
and is not fundamentally worse than any rule family generated by a
meta-theoretic side condition. We also add a similar rule scheme for
equality of terms of type $M$ so that open terms of the resource can
be manipulated by things like commutativity of the
camera. Specifically, we shall add an axiom family like the
following.
\[
  \inferrule{
    \All n, (\eta : \Gamma). \Sem{t_1}_\eta = \Sem{t_2}_\eta
  }{\provesIffJ{\Gamma}{\ownM{t_1}}{\ownM{t_2}}}
\]
Now this is really in some sense a red herring. The addition of these
axioms to the logic if we insist on understanding and manipulating
Iris syntactically as a logic. A far more natural understanding avoids
this odd truth-theoretic detour and approaches the base logic as a
small list of facts that are true in the Iris model where real
reasoning takes place. These rules encode some common patterns of
inference and can be formulated into a well-behaved proof theory
(higher-order bunched implication logic with a few modalities). The
remainder of the ``rules'' are not really rules of the logic at all
but a collection of facts which happen to be true of the model under
consideration. This understanding means that Iris-as-a-logic is quite
useless and ill-suited for proving much of what we want. This
reasoning must instead be done in the model where the . This
disentanglement of Iris-as-a-logic and Iris as a logic and intended
model is crucial to making sense of the ``rules'' of the logic and
what the embedding in Coq actually means. As a matter of future
research I am extremely interested in isolating a usable proof theory
of Iris but this is in fact future research. There has been some work
in the direction of isolating better behaved proof theories and
semantics of them~\citep{Biering:07,Bizjak:17}\footnote{Though these
  two have been confined to semantic investigations, the relative
  generality of the semantics compared to Iris itself has
  \emph{forced} a more sensible proof theory} that may interest some
readers.

Finally, the following axioms are necessary for manipulating validity
in various ways. The most important one of these rules is the second
which captures the fact that we may only ever own valid rules.
\begin{mathpar}
  \inferrule{ }{\provesJ{\Gamma}{\mval(t_1 \cdot t_2)}{\mval(t_1)}}\and
  \inferrule{ }{\provesJ{\Gamma}{\ownM{t}}{\mval(t)}}
\end{mathpar}
With this the Iris logic is an extremely rich framework. It's become
an ideal setting for describing the ownership of elements of a
camera.

\subsection{Guardedness and L\"{o}b Induction}\label{subsec:guarded}

If we want Iris to serve as the framework for constructing various
concurrent separation logics or just generally tools for reasoning
about programs, it becomes clear that it must deal with a recurring
problem in language semantics: recursive definitions. Many of the
hardest technical issues in the semantics of programming languages
arise as questions of how to cook up a mathematical analogue for a
recursive equation of some sort.

Iris internalizes a powerful tool for solving recursive equations:
guarded recursion. Guarded recursion allows for the formation of any
recursive definition with the proviso that all of the recursive
instances must occur below the \emph{later modality}. This later
modality can be thought of indicating that something is not true
currently but will be at the next step or world.

This idea of using a particular modality to encode recursion comes
from the work of \citet{Nakano:00} in the context of productive
recursion. Since Iris is a logic, many of the subtle issues around the
later modality are not problems. This means that the later modality
may be governed by 5 basic rules.
\begin{mathpar}
  \inferrule{
    \Gamma \proves P : \Omega
  }{\Gamma \proves \later P : \Omega}\and
  \inferrule{ }{\provesJ{\Gamma}{P}{\later P}}\and
  \inferrule{ }{\provesJ{\Gamma}{\later P \to P}{P}}\and
  \inferrule{
    \text{$x$ is guarded in $P$}\\
    \Gamma, x : \Omega \proves P : \Omega
  }{\Gamma \proves \MU x. P : \Omega\\\\
    \provesJ{\Gamma}{\TRUE}{\MU x. P = [\MU x. P/x]P}}
\end{mathpar}
The most interesting rules are the last three which govern how the
later modality may be used to create recursive definitions. The third
rule is a principle called L\"ob induction. Since Iris propositions
are understood to be true up to a step-index, $n$, we can prove that a
proposition hold by induction on the step-index. First we show that
it's true at step $0$ (trivial since all propositions are true here)
and then show that truth at step $n$ implies truth at $n + 1$. L\"ob
induction internalizes this because $\later P$ is true when $P$ holds
at the prior step-index. The rule states exactly that if $P$ being
true at $n$ implies that $P$ is true at $n + 1$, then $P$ is true at
all $n$.

The fourth rule is slightly more subtle and governs the formation of
guarded recursive definitions. This actual rule in Iris is more
powerful, allowing the formation of recursive definitions at any
complete type $\tau$ rather than just $\Omega$ but we do not need this
extra generality. The idea of this rule is that $\MU x. P$ can be
justified, like L\"ob induction, by induction on the step. At step $1$
it is equivalent to $[\TRUE/x]P$, at step one it's equivalent to
$[[\TRUE/x]P/x]P$, and so on. This is because the $\later$ modalities
force the step to decrease whenever a recursive call, avoiding the
need to every fully construct $\MU x. P$. A precise justification of
this idea can be found in formal developments of guarded domain
theory~\citep{Birkedal:10,Birkdel:11} and it's latent

More su

\subsection{The Always \& Update Modality}\label{subsec:always}

\section{The Model of Iris}\label{sec:model}

\section{Building a Concurrent Separation Logic}\label{sec:encoding}

\section{Applications}\label{sec:applications}

\section{Conclusion}\label{sec:conclusions}


\bibliographystyle{plainnat}
\bibliography{csl}{}
\end{document}
